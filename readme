
# How to Run
First run the presetup script present in presetup sub-folder
pre-setup/fixed_bootstrap.ps1
Then follow these steps to run the application:
Open Powershell in admin mode and then go the folder where this script is located usimg cd command.
once you complete the presetup script then close the command window.

Then open new posewrsehll window in admin mode-
cd C:\SourceCode\AidMate
Run the script in order 1 -5 as shown below-
01_ollama_setup.ps1
02_patch_port.ps1
03_setup_piper.ps1
04_create_pipeline.ps1
05_setup_whisper.ps1
06_ollama_mini_alias.ps1

Once the above one time script run is completed, going foreard we only need to run below script-
run_aidmate.ps1


# Troubkeshoot purpose###
Once you complete the setup scripts then close the pwershell window (but dont close the ollama server window)
Make sure Ollama is running
If not then start it by running the following command in a new:
powershell
Copy
Edit
& "$env:LOCALAPPDATA\Programs\Ollama\ollama.exe" serve
Start your FastAPI backend

To Run teh Fast API in VS code locally, follow below steps-
# Remove old venv
rmdir .venv -Recurse -Force

# Create a new one with your current python
python -m venv .venv

# Activate it
.\.venv\Scripts\activate

# Upgrade pip
python -m pip install --upgrade pip

# start the web server
uvicorn app:app --host 0.0.0.0 --port 7860 --reload

# Open the UI-
open in folder explorer \web\index.html and open in your browser.
